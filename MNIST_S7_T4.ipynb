{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "from model import MnistNet_4\n",
        "\n",
        "\n",
        "def seed_everything(seed=10):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything(1)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xdydjYTZFyi3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "MnistNet_4                               [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 8, 12, 12]            --\n",
              "│    └─Conv2d: 2-1                       [1, 8, 26, 26]            72\n",
              "│    └─ReLU: 2-2                         [1, 8, 26, 26]            --\n",
              "│    └─BatchNorm2d: 2-3                  [1, 8, 26, 26]            16\n",
              "│    └─Dropout: 2-4                      [1, 8, 26, 26]            --\n",
              "│    └─Conv2d: 2-5                       [1, 16, 24, 24]           1,152\n",
              "│    └─ReLU: 2-6                         [1, 16, 24, 24]           --\n",
              "│    └─BatchNorm2d: 2-7                  [1, 16, 24, 24]           32\n",
              "│    └─Dropout: 2-8                      [1, 16, 24, 24]           --\n",
              "│    └─Conv2d: 2-9                       [1, 8, 24, 24]            128\n",
              "│    └─MaxPool2d: 2-10                   [1, 8, 12, 12]            --\n",
              "├─Sequential: 1-2                        [1, 16, 6, 6]             --\n",
              "│    └─Conv2d: 2-11                      [1, 16, 10, 10]           1,152\n",
              "│    └─ReLU: 2-12                        [1, 16, 10, 10]           --\n",
              "│    └─BatchNorm2d: 2-13                 [1, 16, 10, 10]           32\n",
              "│    └─Dropout: 2-14                     [1, 16, 10, 10]           --\n",
              "│    └─Conv2d: 2-15                      [1, 16, 8, 8]             2,304\n",
              "│    └─ReLU: 2-16                        [1, 16, 8, 8]             --\n",
              "│    └─BatchNorm2d: 2-17                 [1, 16, 8, 8]             32\n",
              "│    └─Dropout: 2-18                     [1, 16, 8, 8]             --\n",
              "│    └─Conv2d: 2-19                      [1, 16, 6, 6]             2,304\n",
              "│    └─ReLU: 2-20                        [1, 16, 6, 6]             --\n",
              "│    └─BatchNorm2d: 2-21                 [1, 16, 6, 6]             32\n",
              "│    └─Dropout: 2-22                     [1, 16, 6, 6]             --\n",
              "├─AdaptiveAvgPool2d: 1-3                 [1, 16, 1, 1]             --\n",
              "├─Sequential: 1-4                        [1, 10, 1, 1]             --\n",
              "│    └─Conv2d: 2-23                      [1, 10, 1, 1]             160\n",
              "==========================================================================================\n",
              "Total params: 7,416\n",
              "Trainable params: 7,416\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 1.13\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.32\n",
              "Params size (MB): 0.03\n",
              "Estimated Total Size (MB): 0.35\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MnistNet_4()\n",
        "summary(model, input_size=(1, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DATALOADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "outputs": [],
      "source": [
        "# torch.manual_seed(1)\n",
        "# if use_cuda:\n",
        "#     torch.cuda.manual_seed(1)\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
        "                        transforms.RandomAffine(degrees=10,  scale=(0.95, 1.05)),\n",
        "                        # transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "                    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "                    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TRAINING & TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'Epoch={epoch} Batch={batch_idx} loss={loss.item():.7f} Accuracy={100. * correct / len(train_loader.dataset):.2f}%')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.7f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RUN-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MMWbLWO6FuHb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 2.0000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=0 Batch=468 loss=0.2332005 Accuracy=88.78%: 100%|██████████| 469/469 [00:10<00:00, 45.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0005583, Accuracy: 9810/10000 (98.10%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=1 Batch=468 loss=0.1177745 Accuracy=97.14%: 100%|██████████| 469/469 [00:10<00:00, 43.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0003588, Accuracy: 9865/10000 (98.65%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=2 Batch=468 loss=0.0327818 Accuracy=97.79%: 100%|██████████| 469/469 [00:10<00:00, 43.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0003422, Accuracy: 9870/10000 (98.70%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=3 Batch=468 loss=0.0834121 Accuracy=98.06%: 100%|██████████| 469/469 [00:10<00:00, 42.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0002492, Accuracy: 9904/10000 (99.04%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=4 Batch=468 loss=0.0423025 Accuracy=98.18%: 100%|██████████| 469/469 [00:10<00:00, 43.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0002736, Accuracy: 9898/10000 (98.98%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=5 Batch=468 loss=0.0496761 Accuracy=98.33%: 100%|██████████| 469/469 [00:10<00:00, 43.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0002564, Accuracy: 9905/10000 (99.05%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=6 Batch=468 loss=0.0931766 Accuracy=98.65%: 100%|██████████| 469/469 [00:10<00:00, 43.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001769, Accuracy: 9929/10000 (99.29%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=7 Batch=468 loss=0.0593294 Accuracy=98.71%: 100%|██████████| 469/469 [00:10<00:00, 44.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001769, Accuracy: 9929/10000 (99.29%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=8 Batch=468 loss=0.0138066 Accuracy=98.80%: 100%|██████████| 469/469 [00:10<00:00, 43.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001719, Accuracy: 9925/10000 (99.25%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=9 Batch=468 loss=0.0636003 Accuracy=98.76%: 100%|██████████| 469/469 [00:10<00:00, 43.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001719, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=10 Batch=468 loss=0.0541260 Accuracy=98.78%: 100%|██████████| 469/469 [00:10<00:00, 43.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001693, Accuracy: 9933/10000 (99.33%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0000e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=11 Batch=468 loss=0.0402437 Accuracy=98.76%: 100%|██████████| 469/469 [00:10<00:00, 44.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001648, Accuracy: 9936/10000 (99.36%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0000e-04.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=12 Batch=468 loss=0.0087945 Accuracy=98.83%: 100%|██████████| 469/469 [00:10<00:00, 43.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001919, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0000e-04.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=13 Batch=468 loss=0.0627999 Accuracy=98.87%: 100%|██████████| 469/469 [00:10<00:00, 44.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001750, Accuracy: 9935/10000 (99.35%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0000e-04.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=14 Batch=468 loss=0.0068103 Accuracy=98.82%: 100%|██████████| 469/469 [00:10<00:00, 43.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001918, Accuracy: 9936/10000 (99.36%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0000e-04.\n"
          ]
        }
      ],
      "source": [
        "model = MnistNet_4().to(device)\n",
        "# 99.33\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.04, momentum=0.9)          \n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.2, verbose=True)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1, verbose=True)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "for epoch in range(15):\n",
        "    train(model, device, train_loader, optimizer, criterion, epoch)\n",
        "    test(model, device, test_loader, criterion)\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Target\n",
        "- Try to reduce parameters to near 8K\n",
        "- Try adding batch normalization and regularization\n",
        "- Try above 2 at the same time\n",
        "\n",
        "# Result\n",
        "- RUN-1 with just 7,416 parameters without batch normalization and regularization:\n",
        "    - Parameters: 7,416\n",
        "    - Best Training Accuracy: 98.91%\n",
        "    - Best Test Accuracy: 98.59%\n",
        "- RUN-2 with 7,416 parameters with batch normalization and regularization:\n",
        "    - Parameters: 7,416\n",
        "    - Best Training Accuracy: 99.23%\n",
        "    - Best Test Accuracy: 99.14%\n",
        "\n",
        "# Analysis\n",
        "- Train-test gap is as minimal as possible\n",
        "- able to reach 99.14% test accuracy, potential to reach 99.4% at least after adding image augmentation and GAP"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
