{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "from model import MnistNet_1\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xdydjYTZFyi3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "MnistNet_1                               [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 8, 11, 11]            --\n",
              "│    └─Conv2d: 2-1                       [1, 8, 26, 26]            72\n",
              "│    └─ReLU: 2-2                         [1, 8, 26, 26]            --\n",
              "│    └─Conv2d: 2-3                       [1, 16, 24, 24]           1,152\n",
              "│    └─ReLU: 2-4                         [1, 16, 24, 24]           --\n",
              "│    └─Conv2d: 2-5                       [1, 16, 22, 22]           2,304\n",
              "│    └─ReLU: 2-6                         [1, 16, 22, 22]           --\n",
              "│    └─Conv2d: 2-7                       [1, 8, 22, 22]            128\n",
              "│    └─MaxPool2d: 2-8                    [1, 8, 11, 11]            --\n",
              "├─Sequential: 1-2                        [1, 10, 5, 5]             --\n",
              "│    └─Conv2d: 2-9                       [1, 8, 9, 9]              576\n",
              "│    └─ReLU: 2-10                        [1, 8, 9, 9]              --\n",
              "│    └─Conv2d: 2-11                      [1, 8, 7, 7]              576\n",
              "│    └─ReLU: 2-12                        [1, 8, 7, 7]              --\n",
              "│    └─Conv2d: 2-13                      [1, 16, 5, 5]             1,152\n",
              "│    └─ReLU: 2-14                        [1, 16, 5, 5]             --\n",
              "│    └─Conv2d: 2-15                      [1, 10, 5, 5]             160\n",
              "│    └─ReLU: 2-16                        [1, 10, 5, 5]             --\n",
              "├─Sequential: 1-3                        [1, 10, 1, 1]             --\n",
              "│    └─Conv2d: 2-17                      [1, 10, 1, 1]             2,500\n",
              "==========================================================================================\n",
              "Total params: 8,620\n",
              "Trainable params: 8,620\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 2.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.22\n",
              "Params size (MB): 0.03\n",
              "Estimated Total Size (MB): 0.26\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MnistNet_1()\n",
        "summary(model, input_size=(1, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DATALOADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "if use_cuda:\n",
        "    torch.cuda.manual_seed(1)\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        # transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
        "                        # transforms.RandomAffine(degrees=10,  scale=(0.95, 1.05)),\n",
        "                        # transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "                    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "                    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TRAINING & TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'Epoch={epoch} Batch={batch_idx} loss={loss.item():.7f} Accuracy={100. * correct / len(train_loader.dataset):.2f}%')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.7f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MMWbLWO6FuHb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=0 Batch=468 loss=2.3021410 Accuracy=14.03%: 100%|██████████| 469/469 [00:05<00:00, 79.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0181878, Accuracy: 1682/10000 (16.82%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=1 Batch=468 loss=0.1666424 Accuracy=45.83%: 100%|██████████| 469/469 [00:06<00:00, 76.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0028808, Accuracy: 8915/10000 (89.15%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=2 Batch=468 loss=0.0895845 Accuracy=93.52%: 100%|██████████| 469/469 [00:06<00:00, 77.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0011953, Accuracy: 9538/10000 (95.38%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=3 Batch=468 loss=0.1695518 Accuracy=95.92%: 100%|██████████| 469/469 [00:06<00:00, 76.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0008362, Accuracy: 9658/10000 (96.58%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=4 Batch=468 loss=0.1363637 Accuracy=96.81%: 100%|██████████| 469/469 [00:06<00:00, 77.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0006801, Accuracy: 9724/10000 (97.24%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=5 Batch=468 loss=0.1017923 Accuracy=97.25%: 100%|██████████| 469/469 [00:06<00:00, 74.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0006071, Accuracy: 9768/10000 (97.68%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=6 Batch=468 loss=0.0555718 Accuracy=97.55%: 100%|██████████| 469/469 [00:06<00:00, 76.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0004886, Accuracy: 9804/10000 (98.04%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=7 Batch=468 loss=0.1792802 Accuracy=97.81%: 100%|██████████| 469/469 [00:06<00:00, 77.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0005028, Accuracy: 9813/10000 (98.13%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=8 Batch=468 loss=0.0855415 Accuracy=97.98%: 100%|██████████| 469/469 [00:06<00:00, 74.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0004819, Accuracy: 9801/10000 (98.01%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=9 Batch=468 loss=0.0208282 Accuracy=98.07%: 100%|██████████| 469/469 [00:06<00:00, 78.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0003952, Accuracy: 9837/10000 (98.37%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=10 Batch=468 loss=0.0225720 Accuracy=98.20%: 100%|██████████| 469/469 [00:05<00:00, 78.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0004437, Accuracy: 9834/10000 (98.34%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=11 Batch=468 loss=0.0932789 Accuracy=98.34%: 100%|██████████| 469/469 [00:05<00:00, 79.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0004042, Accuracy: 9833/10000 (98.33%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=12 Batch=468 loss=0.0520834 Accuracy=98.49%: 100%|██████████| 469/469 [00:06<00:00, 74.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0003858, Accuracy: 9834/10000 (98.34%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=13 Batch=468 loss=0.0801769 Accuracy=98.42%: 100%|██████████| 469/469 [00:06<00:00, 74.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0004621, Accuracy: 9811/10000 (98.11%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=14 Batch=468 loss=0.0116184 Accuracy=98.66%: 100%|██████████| 469/469 [00:06<00:00, 74.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0004304, Accuracy: 9824/10000 (98.24%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = MnistNet_1().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(15):\n",
        "    train(model, device, train_loader, optimizer, criterion, epoch)\n",
        "    test(model, device, test_loader, criterion) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Target\n",
        "- Try to reduce parameters to near 8K with more than 98% test accuracy within 10 epochs\n",
        "- Try without Batch normalization and regularization\n",
        "\n",
        "# Result\n",
        "- Parameters: 8,620\n",
        "- Best Training Accuracy: 98.66%\n",
        "- Best Test Accuracy: 98.37%\n",
        "\n",
        "# Analysis\n",
        "- Ignoring first few epochs, before 10 epochs, the model looks like underfitting.\n",
        "- After 10 epochs, the train & test gap is getting narrower and training accuracy is getting higher compared to test accuracy.\n",
        "- Need to reduce parameters to less than 8k and improve model skeleton.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
