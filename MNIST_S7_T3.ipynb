{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "from model import MnistNet_3\n",
        "\n",
        "\n",
        "def seed_everything(seed=10):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "seed_everything(1)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xdydjYTZFyi3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "MnistNet_3                               [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 8, 12, 12]            --\n",
              "│    └─Conv2d: 2-1                       [1, 8, 26, 26]            72\n",
              "│    └─BatchNorm2d: 2-2                  [1, 8, 26, 26]            16\n",
              "│    └─ReLU: 2-3                         [1, 8, 26, 26]            --\n",
              "│    └─Dropout: 2-4                      [1, 8, 26, 26]            --\n",
              "│    └─Conv2d: 2-5                       [1, 16, 24, 24]           1,152\n",
              "│    └─BatchNorm2d: 2-6                  [1, 16, 24, 24]           32\n",
              "│    └─ReLU: 2-7                         [1, 16, 24, 24]           --\n",
              "│    └─Dropout: 2-8                      [1, 16, 24, 24]           --\n",
              "│    └─Conv2d: 2-9                       [1, 8, 24, 24]            128\n",
              "│    └─MaxPool2d: 2-10                   [1, 8, 12, 12]            --\n",
              "├─Sequential: 1-2                        [1, 16, 6, 6]             --\n",
              "│    └─Conv2d: 2-11                      [1, 12, 10, 10]           864\n",
              "│    └─ReLU: 2-12                        [1, 12, 10, 10]           --\n",
              "│    └─BatchNorm2d: 2-13                 [1, 12, 10, 10]           24\n",
              "│    └─Dropout: 2-14                     [1, 12, 10, 10]           --\n",
              "│    └─Conv2d: 2-15                      [1, 16, 8, 8]             1,728\n",
              "│    └─ReLU: 2-16                        [1, 16, 8, 8]             --\n",
              "│    └─BatchNorm2d: 2-17                 [1, 16, 8, 8]             32\n",
              "│    └─Dropout: 2-18                     [1, 16, 8, 8]             --\n",
              "│    └─Conv2d: 2-19                      [1, 16, 6, 6]             2,304\n",
              "│    └─ReLU: 2-20                        [1, 16, 6, 6]             --\n",
              "│    └─BatchNorm2d: 2-21                 [1, 16, 6, 6]             32\n",
              "│    └─Dropout: 2-22                     [1, 16, 6, 6]             --\n",
              "├─AdaptiveAvgPool2d: 1-3                 [1, 16, 1, 1]             --\n",
              "├─Sequential: 1-4                        [1, 10, 1, 1]             --\n",
              "│    └─Conv2d: 2-23                      [1, 10, 1, 1]             160\n",
              "==========================================================================================\n",
              "Total params: 6,544\n",
              "Trainable params: 6,544\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 1.07\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.32\n",
              "Params size (MB): 0.03\n",
              "Estimated Total Size (MB): 0.35\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MnistNet_3()\n",
        "summary(model, input_size=(1, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DATALOADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "if use_cuda:\n",
        "    torch.cuda.manual_seed(1)\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
        "                        transforms.RandomAffine(degrees=15),  # scale=(0.95, 1.05)),       # 5, 10, 15\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "                    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "                    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TRAINING & TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'Epoch={epoch} Batch={batch_idx} loss={loss.item():.7f} Accuracy={100. * correct / len(train_loader.dataset):.2f}%')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.7f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MMWbLWO6FuHb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 5.0000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=0 Batch=468 loss=0.0506339 Accuracy=90.56%: 100%|██████████| 469/469 [00:10<00:00, 46.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0007933, Accuracy: 9711/10000 (97.11%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 5.0000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=1 Batch=468 loss=0.0882496 Accuracy=97.37%: 100%|██████████| 469/469 [00:10<00:00, 46.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0003369, Accuracy: 9859/10000 (98.59%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 5.0000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=2 Batch=468 loss=0.1382393 Accuracy=97.76%: 100%|██████████| 469/469 [00:10<00:00, 46.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0003078, Accuracy: 9869/10000 (98.69%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 5.0000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=3 Batch=468 loss=0.1314877 Accuracy=98.00%: 100%|██████████| 469/469 [00:10<00:00, 45.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0002391, Accuracy: 9900/10000 (99.00%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.7500e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=4 Batch=468 loss=0.0214672 Accuracy=98.47%: 100%|██████████| 469/469 [00:10<00:00, 45.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001982, Accuracy: 9924/10000 (99.24%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.7500e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=5 Batch=468 loss=0.0650054 Accuracy=98.65%: 100%|██████████| 469/469 [00:10<00:00, 45.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001928, Accuracy: 9917/10000 (99.17%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.7500e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=6 Batch=468 loss=0.0137649 Accuracy=98.62%: 100%|██████████| 469/469 [00:10<00:00, 45.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001876, Accuracy: 9924/10000 (99.24%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.7500e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=7 Batch=468 loss=0.0361735 Accuracy=98.62%: 100%|██████████| 469/469 [00:10<00:00, 45.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001644, Accuracy: 9936/10000 (99.36%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 6.1250e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=8 Batch=468 loss=0.0236110 Accuracy=98.69%: 100%|██████████| 469/469 [00:10<00:00, 46.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001676, Accuracy: 9936/10000 (99.36%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 6.1250e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=9 Batch=468 loss=0.0207121 Accuracy=98.78%: 100%|██████████| 469/469 [00:10<00:00, 45.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001554, Accuracy: 9945/10000 (99.45%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 6.1250e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=10 Batch=468 loss=0.0341703 Accuracy=98.80%: 100%|██████████| 469/469 [00:10<00:00, 44.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001628, Accuracy: 9942/10000 (99.42%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 6.1250e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=11 Batch=468 loss=0.0304645 Accuracy=98.78%: 100%|██████████| 469/469 [00:10<00:00, 45.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001602, Accuracy: 9941/10000 (99.41%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.1437e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=12 Batch=468 loss=0.0260025 Accuracy=98.92%: 100%|██████████| 469/469 [00:10<00:00, 45.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001555, Accuracy: 9942/10000 (99.42%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.1437e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=13 Batch=468 loss=0.0471064 Accuracy=98.91%: 100%|██████████| 469/469 [00:10<00:00, 45.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001560, Accuracy: 9941/10000 (99.41%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.1437e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=14 Batch=468 loss=0.0130037 Accuracy=98.88%: 100%|██████████| 469/469 [00:10<00:00, 45.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001537, Accuracy: 9940/10000 (99.40%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.1437e-03.\n"
          ]
        }
      ],
      "source": [
        "model = MnistNet_3().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.35, verbose=True)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "for epoch in range(15):\n",
        "    train(model, device, train_loader, optimizer, criterion, epoch)\n",
        "    test(model, device, test_loader, criterion)\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Target\n",
        "- Reduce parameters to less than 7K\n",
        "- Batch normalization and regularization\n",
        "- Play around learning rate and scheduler configuration\n",
        "\n",
        "# Result\n",
        "- Parameters: 6,544\n",
        "- Best Training Accuracy: 98.92%\n",
        "- Best Test Accuracy: 99.45%\n",
        "\n",
        "# Analysis\n",
        "- Consistent test accuracy from 9th epoch >= 99.4%\n",
        "- Train-test gap can be seen as train accuracy doesn't reach 99%"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
