{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "from model import MnistNet_2\n",
        "\n",
        "\n",
        "def seed_everything(seed=10):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "seed_everything(1)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xdydjYTZFyi3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "MnistNet_4                               [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 8, 12, 12]            --\n",
              "│    └─Conv2d: 2-1                       [1, 8, 26, 26]            72\n",
              "│    └─ReLU: 2-2                         [1, 8, 26, 26]            --\n",
              "│    └─BatchNorm2d: 2-3                  [1, 8, 26, 26]            16\n",
              "│    └─Dropout: 2-4                      [1, 8, 26, 26]            --\n",
              "│    └─Conv2d: 2-5                       [1, 16, 24, 24]           1,152\n",
              "│    └─ReLU: 2-6                         [1, 16, 24, 24]           --\n",
              "│    └─BatchNorm2d: 2-7                  [1, 16, 24, 24]           32\n",
              "│    └─Dropout: 2-8                      [1, 16, 24, 24]           --\n",
              "│    └─Conv2d: 2-9                       [1, 8, 24, 24]            128\n",
              "│    └─MaxPool2d: 2-10                   [1, 8, 12, 12]            --\n",
              "├─Sequential: 1-2                        [1, 16, 6, 6]             --\n",
              "│    └─Conv2d: 2-11                      [1, 16, 10, 10]           1,152\n",
              "│    └─ReLU: 2-12                        [1, 16, 10, 10]           --\n",
              "│    └─BatchNorm2d: 2-13                 [1, 16, 10, 10]           32\n",
              "│    └─Dropout: 2-14                     [1, 16, 10, 10]           --\n",
              "│    └─Conv2d: 2-15                      [1, 16, 8, 8]             2,304\n",
              "│    └─ReLU: 2-16                        [1, 16, 8, 8]             --\n",
              "│    └─BatchNorm2d: 2-17                 [1, 16, 8, 8]             32\n",
              "│    └─Dropout: 2-18                     [1, 16, 8, 8]             --\n",
              "│    └─Conv2d: 2-19                      [1, 16, 6, 6]             2,304\n",
              "│    └─ReLU: 2-20                        [1, 16, 6, 6]             --\n",
              "│    └─BatchNorm2d: 2-21                 [1, 16, 6, 6]             32\n",
              "│    └─Dropout: 2-22                     [1, 16, 6, 6]             --\n",
              "├─AdaptiveAvgPool2d: 1-3                 [1, 16, 1, 1]             --\n",
              "├─Sequential: 1-4                        [1, 10, 1, 1]             --\n",
              "│    └─Conv2d: 2-23                      [1, 10, 1, 1]             160\n",
              "==========================================================================================\n",
              "Total params: 7,416\n",
              "Trainable params: 7,416\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 1.13\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.32\n",
              "Params size (MB): 0.03\n",
              "Estimated Total Size (MB): 0.35\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MnistNet_2()\n",
        "summary(model, input_size=(1, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DATALOADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
        "                        transforms.RandomAffine(degrees=15),  # ,  scale=(0.95, 1.05)),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "                    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "                    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TRAINING & TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'Epoch={epoch} Batch={batch_idx} loss={loss.item():.7f} Accuracy={100. * correct / len(train_loader.dataset):.2f}%')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.7f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MMWbLWO6FuHb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 7.5000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=0 Batch=468 loss=0.1479667 Accuracy=92.80%: 100%|██████████| 469/469 [00:10<00:00, 45.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0003707, Accuracy: 9855/10000 (98.55%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 7.5000e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=1 Batch=468 loss=0.0885876 Accuracy=97.39%: 100%|██████████| 469/469 [00:10<00:00, 44.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0002947, Accuracy: 9886/10000 (98.86%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 4.8750e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=2 Batch=468 loss=0.0137194 Accuracy=98.06%: 100%|██████████| 469/469 [00:10<00:00, 45.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0002271, Accuracy: 9907/10000 (99.07%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 4.8750e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=3 Batch=468 loss=0.0606191 Accuracy=98.16%: 100%|██████████| 469/469 [00:10<00:00, 45.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0002112, Accuracy: 9902/10000 (99.02%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 3.1688e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=4 Batch=468 loss=0.0453521 Accuracy=98.35%: 100%|██████████| 469/469 [00:10<00:00, 45.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001989, Accuracy: 9928/10000 (99.28%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 3.1688e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=5 Batch=468 loss=0.0913020 Accuracy=98.49%: 100%|██████████| 469/469 [00:10<00:00, 45.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001853, Accuracy: 9924/10000 (99.24%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0597e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=6 Batch=468 loss=0.1289853 Accuracy=98.64%: 100%|██████████| 469/469 [00:10<00:00, 44.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001501, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 2.0597e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=7 Batch=468 loss=0.0655444 Accuracy=98.64%: 100%|██████████| 469/469 [00:10<00:00, 44.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001657, Accuracy: 9929/10000 (99.29%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.3388e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=8 Batch=468 loss=0.0361441 Accuracy=98.69%: 100%|██████████| 469/469 [00:10<00:00, 45.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001558, Accuracy: 9936/10000 (99.36%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.3388e-02.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=9 Batch=468 loss=0.0231169 Accuracy=98.72%: 100%|██████████| 469/469 [00:10<00:00, 44.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001445, Accuracy: 9941/10000 (99.41%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 8.7022e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=10 Batch=468 loss=0.0279460 Accuracy=98.72%: 100%|██████████| 469/469 [00:10<00:00, 46.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001422, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 8.7022e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=11 Batch=468 loss=0.1083443 Accuracy=98.79%: 100%|██████████| 469/469 [00:10<00:00, 45.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001459, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 5.6564e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=12 Batch=468 loss=0.0243121 Accuracy=98.83%: 100%|██████████| 469/469 [00:10<00:00, 45.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001575, Accuracy: 9947/10000 (99.47%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 5.6564e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=13 Batch=468 loss=0.0625362 Accuracy=98.87%: 100%|██████████| 469/469 [00:10<00:00, 45.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001386, Accuracy: 9940/10000 (99.40%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 3.6767e-03.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch=14 Batch=468 loss=0.0151680 Accuracy=98.85%: 100%|██████████| 469/469 [00:10<00:00, 45.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0001644, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 3.6767e-03.\n"
          ]
        }
      ],
      "source": [
        "model = MnistNet_2().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.075,momentum=0.9, nesterov=True)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=2, gamma=0.65, verbose=True)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "for epoch in range(15):\n",
        "    train(model, device, train_loader, optimizer, criterion, epoch)\n",
        "    test(model, device, test_loader, criterion)\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Target\n",
        "- Parameters < 8K\n",
        "- Batch normalization and regularization\n",
        "\n",
        "# Result\n",
        "- Parameters: 7,416\n",
        "- Best Training Accuracy: 98.87%\n",
        "- Best Test Accuracy: 99.47%\n",
        "\n",
        "# Analysis\n",
        "- Test accuracy reached 99.47% but consistency is not good enough\n",
        "- Train-test gap can be seen as train accuracy doesn't reach 99%\n",
        "- Can try to reduce parameters futher below 7k and tweak around dropout rate a bit more"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
